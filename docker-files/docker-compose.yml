x-superset-image: &superset-image apachesuperset.docker.scarf.sh/apache/superset:${TAG:-latest-dev}
x-superset-user: &superset-user root
# x-superset-depends-on: &superset-depends-on
#   - db
#   - redis
# x-superset-volumes: &superset-volumes
#   # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container
#   - ./docker:/app/docker
#   - ./superset:/app/superset
#   - ./superset-frontend:/app/superset-frontend
#   - superset_home:/app/superset_home
#   - ./tests:/app/tests


version: "3"

services:

#Hadoop 
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9010:9000
    volumes:
      - "./volume/hadoop_namenode:/hadoop/dfs/name"
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    env_file:
      - ./hadoop-hive.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - "./volume/hadoop_datanode:/hadoop/dfs/data"
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
    ports:
      - "9864:9864"
    env_file:
      - ./hadoop-hive.env

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop-hive.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop-hive.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - "./volume/hadoop_historyserver:/hadoop/yarn/timeline"
    env_file:
      - ./hadoop-hive.env

#Spark

  spark-master:
    image: bde2020/spark-master:3.0.0-hadoop3.2
    container_name: spark-master
    depends_on:
      - namenode
      - datanode
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000

  spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=8g

  spark-worker-2:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=8g
  
  spark-worker-3:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-3
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=8g

  spark-worker-4:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-4
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=8g

  spark-worker-5:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-5
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=8g

  spark-worker-6:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-6
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=8g 



#Zeppelin

  zeppelin:
    image: apache/zeppelin:0.8.0
    ports:
      - "8090:8080"
    volumes:
      - "./volume/spark:/zeppelin/spark"
      - "./volume/notebooks:/zeppelin/notebook"
    environment:
      - "MASTER=spark://spark-master:7077"
      - "SPARK_MASTER=spark://spark-master:7077"
      - "SPARK_HOME=/zeppelin/spark"
      
#Hive

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    depends_on:
      - namenode
      - datanode
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
      - "10002:10002"

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql

  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    container_name: presto-coordinator
    ports:
      - "8089:8089"

#Hue
  hue:
    image: gethue/hue:20201215-135001
    hostname: hue
    container_name: hue
    ports:
      - "8888:8888"
    volumes:
      - ./conf/hue/z-hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
      - ./conf/hue/log.conf:/usr/share/hue/desktop/conf/log.conf
      - ./conf/hive-conf/:/etc/hive/conf/
    depends_on:
    - database

  database:
    image: mysql:8.0
    hostname: database
    container_name: database
    env_file:
      - ./env/database.env
    command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci --init-connect='SET NAMES UTF8;' --innodb-flush-log-at-trx-commit=0
    volumes:
      - ./db/data:/var/lib/mysql
      - ./db/sql:/docker-entrypoint-initdb.d
#      - ./db/my.cnf:/etc/mysql/conf.d/my.cnf

  # huedb:
  #   image: postgres:12.1-alpine
  #   container_name: huedb
  #   volumes:
  #       - pg_data:/var/lib/postgresl/data/
  #   ports:
  #     - "5432"
  #   env_file:
  #     - ./hadoop-hive.env
  #   environment:
  #       SERVICE_PRECONDITION: "namenode:9870 hive-metastore-postgresql:5432 hive-metastore:9083" #datanode:9875 


  # hue:
  #   image: gethue/hue:4.6.0
  #   container_name: hue
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9870 hive-metastore-postgresql:5432 hive-metastore:9083 huedb:980" #datanode:9875 
  #   ports:
  #   - "8989:8888"
  #   volumes:
  #     - ./hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue.ini
  #   # depends_on:
  #   links:
  #     - huedb



#Superset
  redis:
    image: redis:7
    container_name: superset_cache
    restart: unless-stopped
    volumes:
      - "./volume/superset/redis:/data"

  db:
    env_file: docker/.env-non-dev
    image: postgres:14
    container_name: superset_db
    restart: unless-stopped
    volumes:
      - "./volume/superset/db_home:/var/lib/postgresql/data"

  superset:
    env_file: docker/.env-non-dev
    image: *superset-image
    container_name: superset_app
    command: ["/app/docker/docker-bootstrap.sh", "app-gunicorn"]
    user: "root"
    restart: unless-stopped
    ports:
      - 8008:8088
    depends_on:
      - db
      - redis
    volumes: 
      - ./docker:/app/docker
      - "./volume/superset/superset_home:/app/superset_home"

  superset-init:
    image: *superset-image
    container_name: superset_init
    command: ["/app/docker/docker-init.sh"]
    env_file: docker/.env-non-dev
    depends_on:
      - db
      - redis
    user: "root"
    volumes:
      - ./docker:/app/docker
      - "./volume/superset/superset_home:/app/superset_home"
    healthcheck:
      disable: true

  superset-worker:
    image: *superset-image
    container_name: superset_worker
    command: ["/app/docker/docker-bootstrap.sh", "worker"]
    env_file: docker/.env-non-dev
    restart: unless-stopped
    depends_on:
      - db
      - redis
    user: "root"
    volumes:
      - ./docker:/app/docker
      - "./volume/superset/superset_home:/app/superset_home"

    healthcheck:
      test: ["CMD-SHELL", "celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME"]

  # superset-worker-beat:
  #   image: *superset-image
  #   container_name: superset_worker_beat
  #   command: ["/app/docker/docker-bootstrap.sh", "beat"]
  #   env_file: docker/.env-non-dev
  #   restart: "no"
  #   depends_on:
  #     - db
  #     - redis
  #   user: "root"
  #   volumes:
  #     - ./docker:/app/docker
  #     - "./volume/superset/superset_home:/app/superset_home"
  #   healthcheck:
  #     disable: true


# #Superset
#   redis:
#     image: redis:7
#     container_name: superset_cache
#     restart: unless-stopped
#     ports:
#       - "127.0.0.1:6379:6379"
#     volumes:
#       - redis:/data

#   db:
#     env_file: docker/.env
#     image: postgres:14
#     container_name: superset_db
#     restart: unless-stopped
#     ports:
#       - "127.0.0.1:543x:543x" # 5432 hive-meta-store
#     volumes:
#       - db_home:/var/lib/postgresql/data

#   superset:
#     env_file: docker/.env
#     image: *superset-image
#     container_name: superset_app
#     command: ["/app/docker/docker-bootstrap.sh", "app"]
#     restart: unless-stopped
#     ports:
#       - 8008:8088
#     user: *superset-user
#     depends_on: *superset-depends-on
#     volumes: *superset-volumes
#     environment:
#       CYPRESS_CONFIG: "${CYPRESS_CONFIG}"

#   superset-websocket:
#     container_name: superset_websocket
#     build: ./superset-websocket
#     image: superset-websocket
#     ports:
#       - 8009:8080
#     depends_on:
#       - redis
#     # Mount everything in superset-websocket into container and
#     # then exclude node_modules and dist with bogus volume mount.
#     # This is necessary because host and container need to have
#     # their own, separate versions of these files. .dockerignore
#     # does not seem to work when starting the service through
#     # docker-compose.
#     #
#     # For example, node_modules may contain libs with native bindings.
#     # Those bindings need to be compiled for each OS and the container
#     # OS is not necessarily the same as host OS.
#     volumes:
#       - ./superset-websocket:/home/superset-websocket
#       - /home/superset-websocket/node_modules
#       - /home/superset-websocket/dist
#     environment:
#       - PORT=8009
#       - REDIS_HOST=redis
#       - REDIS_PORT=6379
#       - REDIS_SSL=false

#   superset-init:
#     image: *superset-image
#     container_name: superset_init
#     command: ["/app/docker/docker-init.sh"]
#     env_file: docker/.env
#     depends_on: *superset-depends-on
#     user: *superset-user
#     volumes: *superset-volumes
#     environment:
#       CYPRESS_CONFIG: "${CYPRESS_CONFIG}"
#     healthcheck:
#       disable: true

#   superset-node:
#     image: node:16
#     container_name: superset_node
#     command: ["/app/docker/docker-frontend.sh"]
#     env_file: docker/.env
#     depends_on: *superset-depends-on
#     volumes: *superset-volumes

#   superset-worker:
#     image: *superset-image
#     container_name: superset_worker
#     command: ["/app/docker/docker-bootstrap.sh", "worker"]
#     env_file: docker/.env
#     restart: unless-stopped
#     depends_on: *superset-depends-on
#     user: *superset-user
#     volumes: *superset-volumes
#     healthcheck:
#       test: ["CMD-SHELL", "celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME"]
#     # Bump memory limit if processing selenium / thumbnails on superset-worker
#     # mem_limit: 2038m
#     # mem_reservation: 128M

#   superset-worker-beat:
#     image: *superset-image
#     container_name: superset_worker_beat
#     command: ["/app/docker/docker-bootstrap.sh", "beat"]
#     env_file: docker/.env
#     restart: unless-stopped
#     depends_on: *superset-depends-on
#     user: *superset-user
#     volumes: *superset-volumes
#     healthcheck:
#       disable: true

#   superset-tests-worker:
#     image: *superset-image
#     container_name: superset_tests_worker
#     command: ["/app/docker/docker-bootstrap.sh", "worker"]
#     env_file: docker/.env
#     environment:
#       DATABASE_HOST: localhost
#       DATABASE_DB: test
#       REDIS_CELERY_DB: 2
#       REDIS_RESULTS_DB: 3
#       REDIS_HOST: localhost
#     network_mode: host
#     depends_on: *superset-depends-on
#     user: *superset-user
#     volumes: *superset-volumes
#     healthcheck:
#       test: ["CMD-SHELL", "celery inspect ping -A superset.tasks.celery_app:app -d celery@$$HOSTNAME"]


volumes:
  hadoop_namenode:
    external: true
  hadoop_datanode:
    external: true
  hadoop_historyserver:
    external: true
  pg_data:
    external: true
  superset_home:
    external: true
  db_home:
    external: true
  redis:
    external: true